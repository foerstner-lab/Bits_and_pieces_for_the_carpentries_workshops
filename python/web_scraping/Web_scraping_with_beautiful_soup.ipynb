{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4980bae4-39dd-4a1b-9607-ebd22fb23e51",
   "metadata": {},
   "source": [
    "# Webscraping mit der Python Library Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f938ceb-2354-4343-abd6-6483485d192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b08b7a-330c-40d8-b9cc-5182920a2775",
   "metadata": {},
   "source": [
    "Beautiful Soup ist eine Python-Bibliothek, die hauptsächlich zur Extraktion von Informationen aus HTML- und XML-Dokumenten verwendet wird. Mit Beautiful Soup können Sie verschiedene Aufgaben im Zusammenhang mit dem Web-Scraping und der Analyse von Webinhalten ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0cc686-8dae-4908-9494-4481fbd06482",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://dl.acm.org/doi/proceedings/10.1145/2814864\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d775dd6-0724-48b2-8f4a-f9441cee5a32",
   "metadata": {},
   "source": [
    "Die Website \"https://dl.acm.org/\" dient als Portal für die ACM Digital Library. In der ACM Digital Library finden Sie eine umfangreiche Sammlung von wissenschaftlichen Arbeiten, Zeitschriftenartikeln, Konferenzberichten und anderen Publikationen im Bereich der Informatik und Computertechnologie. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed89709-4eb5-451e-a813-1cb0a3179231",
   "metadata": {},
   "source": [
    "Im ersten Schritt verwenden wir die request.get Funktion aus der Bibliothek requests, um eine Anfrage an die URL zu senden un die Webinhalte abzurufen. Das Ergebnis speichern wir direkt in der Variable request ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e8fb4c-501e-4542-ab5e-49808e9258e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cef53-c038-4e73-8916-e793c0323e70",
   "metadata": {},
   "source": [
    "Nun können wir BeautifulSoup verwenden, um den HTML-Inhalt der Webseite zu analysieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ffc3e96-9d9b-41b5-8a32-5d9f2812d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(request.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7100f-6c31-4c2a-b613-d48fbb49cf06",
   "metadata": {},
   "source": [
    "Zuerst wird die Methode request.content verwendet, um den HTML-Inhalt aus der HTTP-Antwort (request) abzurufen. Dann wird \"html.parser\" als Parser angegeben, der verwendet wird, um das HTML-Dokument zu analysieren.\n",
    "\n",
    "Der resultierende soup-Objekt enthält die geparsten und strukturierten Informationen aus dem HTML-Dokument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35043fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582d244-c957-4cc1-a332-8045a157df46",
   "metadata": {},
   "source": [
    "Hier sehen wir unseren analysierten HTML-Inhalt. Aber recht unübersichtlich. Wir können die Methode prettify nutzen, um den HTML Inhalt formatiert und eingerückt zurückzubekommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12cfdf3-8d32-4878-bd48-5c94f26e2b1c",
   "metadata": {},
   "source": [
    "Alternativ könnte man sich den Quelltext auch auf der Seite selbst mit F12 oder einem rechtsklick \"Quelltext untersuchen\" anschauen, um sich einen Überblick zu verschaffen.\n",
    "\n",
    "mit BeautifulSoup können wir uns jetzt einzelne Elemente des HTML Inhalts ausgeben lassen. Zum Beispiel den Titel der Publikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a15d8-4972-4420-a1aa-fdc51890168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prettify(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a772be-0614-4fc1-8db6-fc6240173ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Proceedings of the 11th International Conference on Semantic Systems | ACM Other conferences</title>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3306c",
   "metadata": {},
   "source": [
    "Damit haben wir zwar den Titel, aber auch den tag-name.\n",
    "Mit name bekommen wir nur den tag zurück, mit string nur den Titel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "badc0ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d0ee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proceedings of the 11th International Conference on Semantic Systems | ACM Other conferences'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860c3723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gibt den tag head zurück, da der tag title sich innerhalb dieses tags befinden\n",
    "soup.title.parent.name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7f447",
   "metadata": {},
   "source": [
    "Durchsuchen wir den Inhalt nach a Tags  \n",
    "a-Tags (Anchor-Tags):\n",
    "Die Hauptfunktion von a-Tags besteht darin, Hyperlinks zu anderen Webseiten oder Ressourcen zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wird verwendet, um alle <a>-Tags in einem geparsten HTML-Dokument zu finden \n",
    "# und eine Liste von BeautifulSoup-Tag-Instanzen zurückzugeben, die diese Tags darstellen.\n",
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a9089",
   "metadata": {},
   "source": [
    "Das ganze können wir wiederum übersichtlicher machen, indem wir die einzelnen Rückgaben durch Striche voneinander abtrennen. Dazu können wir eine Schleife bauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in soup.find_all(\"a\"):\n",
    "    print(a)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883cf72",
   "metadata": {},
   "source": [
    "Wir können auch nach Überschriften einer bestimmten Stufe suchen: h1, h2, h3, usw  \n",
    "Suchen wir nach h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f776219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h5>Save to Binder</h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814887\">Crowdsourced semantic annotation of scientific publications and tabular data in PDF</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814870\">Complex event extraction from real-time news streams</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814869\">An elastic and scalable spatiotemporal query processing for linked sensor data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814879\">Toward a statistical data integration environment: the role of semantic metadata</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814867\">The role of reasoning for RDF validation</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814874\">Accessing and reasoning with data from disparate data sources using modular ontologies and OBDA</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814866\">Making sense of description logics</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814875\">TailR: a platform for preserving history on the web of data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814877\">Integrating custom index extensions into virtuoso RDF store for e-commerce applications</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814885\">Knowledge base shipping to the linked open data cloud</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814865\">iCM-Hydraulic: semantics-empowered condition monitoring of hydraulic machines</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814884\">A linked data platform for finite element biosimulations</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814888\">Cross-lingual lexical matching with word translation and local similarity optimization</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814871\">Updating OWL2 ontologies using pruned rulesets</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814868\">A semantic method for multiple resources exploitation</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814886\">SemaGrow: optimizing federated SPARQL queries</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814880\">Streaming transformation of XML to RDF using XPath-based mappings</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814882\">LODFlow: a workflow management system for linked data processing</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814873\">Machine-interpretable dataset and service descriptions for heterogeneous data access and retrieval</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814878\">Data licensing on the cloud: empirical insights and implications for linked data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814876\">An overview of the tourpedia linked dataset with a focus on relations discovery among places</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814872\">An optimization approach for load balancing in parallel link discovery</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814883\">MEX vocabulary: a lightweight interchange format for machine learning experiments</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814881\">Unsupervised learning of an extensive and usable taxonomy for DBpedia</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814893\">Living semantic platform</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814890\">SimplePARQL: a new approach using keywords over SPARQL to query the web of data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814889\">The DBpedia wayback machine</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814892\">Updating SPARQL results in real-time with client-side fragment patching</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814891\">Procurement notice enrichment using product ontologies</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814894\">Online ontology shortest paths searcher</a></h5>,\n",
       " <h5>Save to Binder</h5>,\n",
       " <h5 class=\"creative-work__title truncate-text-css\" data-lines=\"2\">ICETE 2014: Proceedings of the 11th International Joint Conference on e-Business and Telecommunications - Volume 4</h5>,\n",
       " <h5 class=\"creative-work__title truncate-text-css\" data-lines=\"2\">ICETE 2014: Proceedings of the 11th International Joint Conference on e-Business and Telecommunications - Volume 1</h5>,\n",
       " <h5 class=\"creative-work__title truncate-text-css\" data-lines=\"2\">ICETE 2014: Proceedings of the 11th International Joint Conference on e-Business and Telecommunications - Volume 2</h5>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hier sehen wir sowohl die Titel der Artikel, als auch die doi\n",
    "soup.find_all(\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d5247",
   "metadata": {},
   "source": [
    "Unter h5 finden wir alle Artikel und ihre DOI. Die letzen 3 Einträge, zeigen eine andere Klasse (creative-work__title) die wir nicht brauchen. Diese können wir entfernen, indem wir gezielt die class ansprechen, die wir brauchen > issue-item_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341bdbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814887\">Crowdsourced semantic annotation of scientific publications and tabular data in PDF</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814870\">Complex event extraction from real-time news streams</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814869\">An elastic and scalable spatiotemporal query processing for linked sensor data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814879\">Toward a statistical data integration environment: the role of semantic metadata</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814867\">The role of reasoning for RDF validation</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814874\">Accessing and reasoning with data from disparate data sources using modular ontologies and OBDA</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814866\">Making sense of description logics</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814875\">TailR: a platform for preserving history on the web of data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814877\">Integrating custom index extensions into virtuoso RDF store for e-commerce applications</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814885\">Knowledge base shipping to the linked open data cloud</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814865\">iCM-Hydraulic: semantics-empowered condition monitoring of hydraulic machines</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814884\">A linked data platform for finite element biosimulations</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814888\">Cross-lingual lexical matching with word translation and local similarity optimization</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814871\">Updating OWL2 ontologies using pruned rulesets</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814868\">A semantic method for multiple resources exploitation</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814886\">SemaGrow: optimizing federated SPARQL queries</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814880\">Streaming transformation of XML to RDF using XPath-based mappings</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814882\">LODFlow: a workflow management system for linked data processing</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814873\">Machine-interpretable dataset and service descriptions for heterogeneous data access and retrieval</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814878\">Data licensing on the cloud: empirical insights and implications for linked data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814876\">An overview of the tourpedia linked dataset with a focus on relations discovery among places</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814872\">An optimization approach for load balancing in parallel link discovery</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814883\">MEX vocabulary: a lightweight interchange format for machine learning experiments</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814881\">Unsupervised learning of an extensive and usable taxonomy for DBpedia</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814893\">Living semantic platform</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814890\">SimplePARQL: a new approach using keywords over SPARQL to query the web of data</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814889\">The DBpedia wayback machine</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814892\">Updating SPARQL results in real-time with client-side fragment patching</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814891\">Procurement notice enrichment using product ontologies</a></h5>,\n",
       " <h5 class=\"issue-item__title\"><a href=\"/doi/10.1145/2814864.2814894\">Online ontology shortest paths searcher</a></h5>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"h5\", {\"class\":\"issue-item__title\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5109b",
   "metadata": {},
   "source": [
    "Jetzt könnnen wir diese Liste nehmen und uns nur die Strings zurückgeben lassen, wie am anfang, um die reinen Titel zurückzubekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abebbc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowdsourced semantic annotation of scientific publications and tabular data in PDF\n",
      "Complex event extraction from real-time news streams\n",
      "An elastic and scalable spatiotemporal query processing for linked sensor data\n",
      "Toward a statistical data integration environment: the role of semantic metadata\n",
      "The role of reasoning for RDF validation\n",
      "Accessing and reasoning with data from disparate data sources using modular ontologies and OBDA\n",
      "Making sense of description logics\n",
      "TailR: a platform for preserving history on the web of data\n",
      "Integrating custom index extensions into virtuoso RDF store for e-commerce applications\n",
      "Knowledge base shipping to the linked open data cloud\n",
      "iCM-Hydraulic: semantics-empowered condition monitoring of hydraulic machines\n",
      "A linked data platform for finite element biosimulations\n",
      "Cross-lingual lexical matching with word translation and local similarity optimization\n",
      "Updating OWL2 ontologies using pruned rulesets\n",
      "A semantic method for multiple resources exploitation\n",
      "SemaGrow: optimizing federated SPARQL queries\n",
      "Streaming transformation of XML to RDF using XPath-based mappings\n",
      "LODFlow: a workflow management system for linked data processing\n",
      "Machine-interpretable dataset and service descriptions for heterogeneous data access and retrieval\n",
      "Data licensing on the cloud: empirical insights and implications for linked data\n",
      "An overview of the tourpedia linked dataset with a focus on relations discovery among places\n",
      "An optimization approach for load balancing in parallel link discovery\n",
      "MEX vocabulary: a lightweight interchange format for machine learning experiments\n",
      "Unsupervised learning of an extensive and usable taxonomy for DBpedia\n",
      "Living semantic platform\n",
      "SimplePARQL: a new approach using keywords over SPARQL to query the web of data\n",
      "The DBpedia wayback machine\n",
      "Updating SPARQL results in real-time with client-side fragment patching\n",
      "Procurement notice enrichment using product ontologies\n",
      "Online ontology shortest paths searcher\n"
     ]
    }
   ],
   "source": [
    "for publication in soup.find_all(\"h5\", {\"class\":\"issue-item__title\"}):\n",
    "    print(publication.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f1a37",
   "metadata": {},
   "source": [
    "Wenn wir auch die DOIs haben wollen, können wir diese mit in die Sleife einbauen.\n",
    "Um den a tag innerhalb h5 aufzurrufen können wir anstatt find_all(\"a\") in beautfilsoup auch ein .a schreiben. Innerhalb des a tags können wir dann den href tag angeben und das /doi/ durch nicht ersetzen mit replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecd6821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Crowdsourced semantic annotation of scientific publications and tabular data in PDF\n",
      "DOI: 10.1145/2814864.2814887\n",
      "-----\n",
      "Title: Complex event extraction from real-time news streams\n",
      "DOI: 10.1145/2814864.2814870\n",
      "-----\n",
      "Title: An elastic and scalable spatiotemporal query processing for linked sensor data\n",
      "DOI: 10.1145/2814864.2814869\n",
      "-----\n",
      "Title: Toward a statistical data integration environment: the role of semantic metadata\n",
      "DOI: 10.1145/2814864.2814879\n",
      "-----\n",
      "Title: The role of reasoning for RDF validation\n",
      "DOI: 10.1145/2814864.2814867\n",
      "-----\n",
      "Title: Accessing and reasoning with data from disparate data sources using modular ontologies and OBDA\n",
      "DOI: 10.1145/2814864.2814874\n",
      "-----\n",
      "Title: Making sense of description logics\n",
      "DOI: 10.1145/2814864.2814866\n",
      "-----\n",
      "Title: TailR: a platform for preserving history on the web of data\n",
      "DOI: 10.1145/2814864.2814875\n",
      "-----\n",
      "Title: Integrating custom index extensions into virtuoso RDF store for e-commerce applications\n",
      "DOI: 10.1145/2814864.2814877\n",
      "-----\n",
      "Title: Knowledge base shipping to the linked open data cloud\n",
      "DOI: 10.1145/2814864.2814885\n",
      "-----\n",
      "Title: iCM-Hydraulic: semantics-empowered condition monitoring of hydraulic machines\n",
      "DOI: 10.1145/2814864.2814865\n",
      "-----\n",
      "Title: A linked data platform for finite element biosimulations\n",
      "DOI: 10.1145/2814864.2814884\n",
      "-----\n",
      "Title: Cross-lingual lexical matching with word translation and local similarity optimization\n",
      "DOI: 10.1145/2814864.2814888\n",
      "-----\n",
      "Title: Updating OWL2 ontologies using pruned rulesets\n",
      "DOI: 10.1145/2814864.2814871\n",
      "-----\n",
      "Title: A semantic method for multiple resources exploitation\n",
      "DOI: 10.1145/2814864.2814868\n",
      "-----\n",
      "Title: SemaGrow: optimizing federated SPARQL queries\n",
      "DOI: 10.1145/2814864.2814886\n",
      "-----\n",
      "Title: Streaming transformation of XML to RDF using XPath-based mappings\n",
      "DOI: 10.1145/2814864.2814880\n",
      "-----\n",
      "Title: LODFlow: a workflow management system for linked data processing\n",
      "DOI: 10.1145/2814864.2814882\n",
      "-----\n",
      "Title: Machine-interpretable dataset and service descriptions for heterogeneous data access and retrieval\n",
      "DOI: 10.1145/2814864.2814873\n",
      "-----\n",
      "Title: Data licensing on the cloud: empirical insights and implications for linked data\n",
      "DOI: 10.1145/2814864.2814878\n",
      "-----\n",
      "Title: An overview of the tourpedia linked dataset with a focus on relations discovery among places\n",
      "DOI: 10.1145/2814864.2814876\n",
      "-----\n",
      "Title: An optimization approach for load balancing in parallel link discovery\n",
      "DOI: 10.1145/2814864.2814872\n",
      "-----\n",
      "Title: MEX vocabulary: a lightweight interchange format for machine learning experiments\n",
      "DOI: 10.1145/2814864.2814883\n",
      "-----\n",
      "Title: Unsupervised learning of an extensive and usable taxonomy for DBpedia\n",
      "DOI: 10.1145/2814864.2814881\n",
      "-----\n",
      "Title: Living semantic platform\n",
      "DOI: 10.1145/2814864.2814893\n",
      "-----\n",
      "Title: SimplePARQL: a new approach using keywords over SPARQL to query the web of data\n",
      "DOI: 10.1145/2814864.2814890\n",
      "-----\n",
      "Title: The DBpedia wayback machine\n",
      "DOI: 10.1145/2814864.2814889\n",
      "-----\n",
      "Title: Updating SPARQL results in real-time with client-side fragment patching\n",
      "DOI: 10.1145/2814864.2814892\n",
      "-----\n",
      "Title: Procurement notice enrichment using product ontologies\n",
      "DOI: 10.1145/2814864.2814891\n",
      "-----\n",
      "Title: Online ontology shortest paths searcher\n",
      "DOI: 10.1145/2814864.2814894\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for publication in soup.find_all(\"h5\", {\"class\":\"issue-item__title\"}):\n",
    "    print(\"Title:\", publication.string)\n",
    "    print(\"DOI:\", publication.a[\"href\"].replace(\"/doi/\", \"\"))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210a34f",
   "metadata": {},
   "source": [
    "## Ende"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
